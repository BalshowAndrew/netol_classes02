{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccc52919",
   "metadata": {},
   "source": [
    "# Распознавание изображений цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a49f3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5929afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ba122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормируем входные данные в диапазон от 0 до 1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b90886c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8b22451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вытяним данные в один единый вектор\n",
    "x_train = tf.reshape(tf.cast(x_train, tf.float32), [-1, 28*28])\n",
    "x_test = tf.reshape(tf.cast(x_test, tf.float32), [-1, 28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f59a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87c8936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем метку в one-hot вектор\n",
    "y_train = to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3489e172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e77d903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNN(tf.Module):\n",
    "    def __init__(self, outputs, activate=\"relu\"):\n",
    "        super().__init__()\n",
    "        self.outputs = outputs\n",
    "        self.activate = activate\n",
    "        self.fl_init = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.fl_init:\n",
    "            self.w = tf.random.truncated_normal((x.shape[-1], self.outputs), stddev=0.1, name=\"w\")\n",
    "            self.b = tf.zeros([self.outputs], dtype=tf.float32, name='b')\n",
    "\n",
    "            self.w = tf.Variable(self.w)\n",
    "            self.b = tf.Variable(self.b)\n",
    "\n",
    "            self.ft_init = True\n",
    "\n",
    "        y = x @ self.w + self.b\n",
    "        \n",
    "        if self.activate == \"relu\":\n",
    "            return tf.nn.relu(y)\n",
    "        elif self.activate == \"softmax\":\n",
    "            return tf.nn.softmax(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "caaf390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем слои:\n",
    "layer_1 = DenseNN(128)\n",
    "layer_2 = DenseNN(10, activate=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e791749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функцпя, которая будет проепускать вектор x через нейронную сеть\n",
    "def model_predict(x):\n",
    "    y = layer_1(x)\n",
    "    y = layer_2(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7494eb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем функцию потерь\n",
    "cross_entropy = lambda y_true, y_pred: tf.reduce_mean(tf.losses.categorical_crossentropy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b26dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизатор\n",
    "opt = tf.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "001696c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "TOTAL = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea38c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем обучащую выборку на батчи:\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bfacd5b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown variable: <tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     grads = tape.gradient(f_loss, [layer_1.trainable_variables, layer_2.trainable_variables])\n\u001b[32m     11\u001b[39m     opt.apply_gradients(\u001b[38;5;28mzip\u001b[39m(grads[\u001b[32m0\u001b[39m], layer_1.trainable_variables))\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(loss.numpy()) \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/netol_classes/.venv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:463\u001b[39m, in \u001b[36mBaseOptimizer.apply_gradients\u001b[39m\u001b[34m(self, grads_and_vars)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[32m    462\u001b[39m     grads, trainable_variables = \u001b[38;5;28mzip\u001b[39m(*grads_and_vars)\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/netol_classes/.venv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:504\u001b[39m, in \u001b[36mBaseOptimizer.apply\u001b[39m\u001b[34m(self, grads, trainable_variables)\u001b[39m\n\u001b[32m    502\u001b[39m             \u001b[38;5;28mself\u001b[39m.build(trainable_variables)\n\u001b[32m    503\u001b[39m         \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_variables_are_known\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m backend.name_scope(\u001b[38;5;28mself\u001b[39m.name, caller=\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    507\u001b[39m     \u001b[38;5;66;03m# Filter empty gradients.\u001b[39;00m\n\u001b[32m    508\u001b[39m     grads, trainable_variables = \u001b[38;5;28mself\u001b[39m._filter_empty_gradients(\n\u001b[32m    509\u001b[39m         grads, trainable_variables\n\u001b[32m    510\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/netol_classes/.venv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:409\u001b[39m, in \u001b[36mBaseOptimizer._check_variables_are_known\u001b[39m\u001b[34m(self, variables)\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trainable_variables_indices:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    410\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. This optimizer can only \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    411\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbe called for the variables it was originally built with. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mWhen working with a new set of variables, you should \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrecreate a new optimizer instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    414\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: Unknown variable: <tf.Variable 'Variable:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
     ]
    }
   ],
   "source": [
    "# Цикл обучения:\n",
    "\n",
    "\n",
    "for n in range(EPOCHS):\n",
    "    loss = 0\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            f_loss = cross_entropy(y_batch, model_predict(x_batch))\n",
    "        loss += f_loss    \n",
    "        grads = tape.gradient(f_loss, [layer_1.trainable_variables, layer_2.trainable_variables])\n",
    "        opt.apply_gradients(zip(grads[0], layer_1.trainable_variables))\n",
    "        opt.apply_gradients(zip(grads[1], layer_2.trainable_variables))\n",
    "\n",
    "    print(loss.numpy()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_predict(x_test)\n",
    "y2 = tf.argmax(y, axis=1).numpy()\n",
    "acc = len(y_test[y_test == y2])/y_test.shape[0] * 100\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e51789",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.metrics.Accuracy()\n",
    "acc.update_state(y_test, y2)\n",
    "print(acc.result().numpy() * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-kernel",
   "language": "python",
   "name": "new-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
