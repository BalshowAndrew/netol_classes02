{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a0ba75",
   "metadata": {},
   "source": [
    "# Построение воходных конвейеров с использованием tf.data - API-интерфейса Dataset библиотеки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9a45f",
   "metadata": {},
   "source": [
    "Когда набор данны слишком большой и потому не умущается в памяти, нам понадобится загружать данные из основного устройства хранения порциями, т.е. пакет за пакетом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5685529d",
   "metadata": {},
   "source": [
    "## Создание объекта Dataset из существующих тензоров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03cf8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52edcba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.float32, name=None)>\n"
     ]
    }
   ],
   "source": [
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82369e4f",
   "metadata": {},
   "source": [
    "Функция возвратила объект класса `Dataset`, который можно применить для прохода по индивидуальным элементам во входном наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44c0cf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a09b980",
   "metadata": {},
   "source": [
    "Создатим из этого набора данных пакеты с размером 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcc630ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пакет 1: [1.2 3.4]\n",
      "пакет 2: [7.5 4.1]\n",
      "пакет 3: [5. 1.]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(2)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('пакет {}:' .format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae4760b",
   "metadata": {},
   "source": [
    "Если количество элементов в тензоре не желаемому зармеру пакета (batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8c8f36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пакет 1: [1.2 3.4 7.5 4.1]\n",
      "пакет 2: [5. 1.]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(4, drop_remainder=False)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('пакет {}:' .format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3d86e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пакет 1: [1.2 3.4 7.5 4.1]\n"
     ]
    }
   ],
   "source": [
    "ds_batch = ds.batch(4, drop_remainder=True)\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('пакет {}:' .format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a40ce3",
   "metadata": {},
   "source": [
    "## Объединение двух тензоров в общий набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391967e",
   "metadata": {},
   "source": [
    "Часто данные находятся в двух или большем числе тензоров, напимер, тензор признаков и тензор меток. В таких случаях надо построить набор данных, который объединит эти тензоры и позволит извлекать элементы тензоров в кортежах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbdd1530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]\n",
      " [0.605 0.637 0.614]]\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\n",
    "t_y = tf.range(4)\n",
    "\n",
    "print(t_x.numpy())\n",
    "print(t_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b3fb0f",
   "metadata": {},
   "source": [
    "Создадим общий набор данных:\n",
    "1. Создадим два набора данных\n",
    "1. Построим общий набор данных, используя фукнцию `.zip()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83e5f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "# Объединим объекты Dataset в один:\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e19d48",
   "metadata": {},
   "source": [
    "Тензоры объединеты в кортежи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "049dfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.165, 0.901, 0.631], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.435, 0.292, 0.643], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.976, 0.435, 0.66 ], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.605, 0.637, 0.614], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n"
     ]
    }
   ],
   "source": [
    "for example in ds_joint:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68574586",
   "metadata": {},
   "source": [
    "Поличим данные из кортежей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb7ecc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.165 0.901 0.631] y: 0\n",
      "x: [0.435 0.292 0.643] y: 1\n",
      "x: [0.976 0.435 0.66 ] y: 2\n",
      "x: [0.605 0.637 0.614] y: 3\n"
     ]
    }
   ],
   "source": [
    "for example in ds_joint:\n",
    "    print('x:', example[0].numpy(),\n",
    "          'y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6265c",
   "metadata": {},
   "source": [
    "Все это можно сделать, используя метод `tf.data.Dataset.from_tensor_slices():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "608cc496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0.165 0.901 0.631] y: 0\n",
      "x: [0.435 0.292 0.643] y: 1\n",
      "x: [0.976 0.435 0.66 ] y: 2\n",
      "x: [0.605 0.637 0.614] y: 3\n"
     ]
    }
   ],
   "source": [
    "ds_jount = tf.data.Dataset.from_tensor_slices((t_x, t_y))\n",
    "for example in ds_joint:\n",
    "    print('x:', example[0].numpy(),\n",
    "          'y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f6c6e",
   "metadata": {},
   "source": [
    "## Применение трансформации к отдельным элементам набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43247c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [-0.67   0.803  0.262]  y: 0\n",
      " x: [-0.131 -0.416  0.285]  y: 1\n",
      " x: [ 0.952 -0.13   0.32 ]  y: 2\n",
      " x: [0.21  0.273 0.229]  y: 3\n"
     ]
    }
   ],
   "source": [
    "# Трансформируем набор признаков:\n",
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1, y))\n",
    "for example in ds_trans:\n",
    "    print(' x:', example[0].numpy(),\n",
    "          ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc56e6",
   "metadata": {},
   "source": [
    "## Тасование, создание пакетов и повторение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877fcc5",
   "metadata": {},
   "source": [
    "### Создание перетасованной версии набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9057c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: [0.976 0.435 0.66 ]  y: 2\n",
      " x: [0.435 0.292 0.643]  y: 1\n",
      " x: [0.165 0.901 0.631]  y: 0\n",
      " x: [0.605 0.637 0.614]  y: 3\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x))\n",
    "for example in ds:\n",
    "    print(' x:', example[0].numpy(),\n",
    "          ' y:', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98cfc46",
   "metadata": {},
   "source": [
    "Строки тасуются без потери соответствия 1:1 между элементами `x` и `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6181d2b",
   "metadata": {},
   "source": [
    "Аргумент `buffer_size` определяет количество элементов в наборе данных, группируемых перед тасованием. Если выбрать небольшое значение для `buffer_aize`, то нельзя будет обеспечить идеальное тасование набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c3565d",
   "metadata": {},
   "source": [
    "### Создание пакетов из объединенных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39694d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пакет-x:\n",
      " [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]] (2, 3)\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(batch_size=2,\n",
    "                    drop_remainder=False)\n",
    "\n",
    "batch_x, batch_y = next(iter(ds))                    \n",
    "print('Пакет-x:\\n', batch_x.numpy(), batch_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50b04cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пакет-y:\n",
      " [0 1] (2,)\n"
     ]
    }
   ],
   "source": [
    "print('Пакет-y:\\n', batch_y.numpy(), batch_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a169357",
   "metadata": {},
   "source": [
    "Повторим разбитый пакет набора данных три раза:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdbb432f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (1, 3) [3]\n",
      "2 (3, 3) [0 1 2]\n",
      "3 (1, 3) [3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.batch(3).repeat(count=2)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96881c84",
   "metadata": {},
   "source": [
    "Если изменить порядок следования операций, то результат будет другим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "09295d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (3, 3) [0 1 2]\n",
      "1 (3, 3) [3 0 1]\n",
      "2 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d8e13e",
   "metadata": {},
   "source": [
    "## Порядок 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b04b9",
   "metadata": {},
   "source": [
    "тасование --> создание пакетов --> повторение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3860b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [2 1]\n",
      "1 (2, 3) [0 3]\n",
      "2 (2, 3) [0 3]\n",
      "3 (2, 3) [1 2]\n",
      "4 (2, 3) [3 0]\n",
      "5 (2, 3) [1 2]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8034c2c",
   "metadata": {},
   "source": [
    "## Порядок 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd3c95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e84bd558",
   "metadata": {},
   "source": [
    "создание пакетов --> тасование --> повторение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "02fef535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [0 1]\n",
      "1 (2, 3) [2 3]\n",
      "2 (2, 3) [0 1]\n",
      "3 (2, 3) [2 3]\n",
      "4 (2, 3) [2 3]\n",
      "5 (2, 3) [0 1]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d6ae6",
   "metadata": {},
   "source": [
    "## Порядок 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2bef78",
   "metadata": {},
   "source": [
    "создание пакетов --> повторение --> тасование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3ca8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 3) [0 1]\n",
      "1 (2, 3) [0 1]\n",
      "2 (2, 3) [2 3]\n",
      "3 (2, 3) [2 3]\n",
      "4 (2, 3) [0 1]\n",
      "5 (2, 3) [2 3]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.batch(2).repeat(3).shuffle(4)\n",
    "for i, (batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4bf255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-kernel",
   "language": "python",
   "name": "new-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
